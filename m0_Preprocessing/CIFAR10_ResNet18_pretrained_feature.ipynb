{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data.dataloader import DataLoader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Image preprocessing modules\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(size=32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2471, 0.2435, 0.2616])\n",
    "    # inherited from https://github.com/kaidic/LDAM-DRW/blob/master/cifar_train.py\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2471, 0.2435, 0.2616])\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz\n",
      "Extracting ../data/cifar-10-python.tar.gz to ../data/\n",
      "Files already downloaded and verified\n",
      "{6: 5000, 9: 5000, 4: 5000, 1: 5000, 2: 5000, 7: 5000, 8: 5000, 3: 5000, 5: 5000, 0: 5000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:06<00:00, 26568593.51it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter, OrderedDict\n",
    "\n",
    "# CIFAR-10 dataset (imbalanced version for training)\n",
    "train_dataset = CIFAR10(root='../data/', train=True, transform=transform_train, download=True)\n",
    "test_dataset = CIFAR10(root='../data/', train=False, transform=transform_test, download=True)\n",
    "n_train = train_dataset.data.shape[0]\n",
    "n_test = test_dataset.data.shape[0]\n",
    "batch_size_train = n_train\n",
    "batch_size_test = n_test\n",
    "\n",
    "# Data loader\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size_train, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size_test, shuffle=False)\n",
    "print(dict(Counter(train_dataset.targets)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 512)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "import detectors\n",
    "import timm\n",
    "\n",
    "# Pretrained model\n",
    "# https://huggingface.co/edadaltocg/resnet18_cifar10\n",
    "model = timm.create_model(\"resnet18_cifar10\", pretrained=True)\n",
    "# remove the last fully-connected layer, output dimension: 512\n",
    "new_model = torch.nn.Sequential(OrderedDict([*(list(model.named_children())[:-1])]))\n",
    "\n",
    "# testing (validation) features\n",
    "for i, data in enumerate(test_loader):\n",
    "    x, y = data[0], data[1]\n",
    "new_model.eval()\n",
    "with torch.no_grad():\n",
    "    features = new_model(x)\n",
    "X_val, y_val = torch.Tensor.numpy(features), torch.Tensor.numpy(y)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: (5000, 512) (5000,)\n",
      "{8: 500, 9: 500, 4: 500, 7: 500, 3: 500, 6: 500, 2: 500, 1: 500, 5: 500, 0: 500}\n",
      "Testing Set: (5000, 512) (5000,)\n",
      "{6: 500, 0: 500, 1: 500, 9: 500, 3: 500, 7: 500, 8: 500, 5: 500, 2: 500, 4: 500}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_val, y_val, test_size=0.5, random_state=2023, stratify=y_val)\n",
    "print('Training Set:', np.shape(X_train), np.shape(y_train))\n",
    "print(dict(Counter(y_train)))\n",
    "print('Testing Set:', np.shape(X_test), np.shape(y_test))\n",
    "print(dict(Counter(y_test)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "np.save('CIFAR10_ResNet18_pretrain_X_test.npy', X_val)\n",
    "np.save('CIFAR10_ResNet18_pretrain_y_test.npy', y_val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}